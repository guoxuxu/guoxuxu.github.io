<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Paper List</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>

<div class="container">

    <div class="profile-block">

        <div class="profile-img-wrapper">
            <img src="./image/head.jpg" class="profile-img" alt="Profile Photo">
        </div>

        <div class="profile-info">
            <div class="profile-name">Xu Guo</div>

            <div class="profile-desc">
                Postdoctoral Researcher<br>
                Wallenberg-NTU Presidential Postdoctoral Fellow<br>
                Department of Intelligent Systems<br>
                KTH Royal Institue of Technology, Sweden<br>
                Email: xugu AT kth.se

            </div>

            <div class="profile-buttons">
                <a class="link-black" target="_blank" href="https://scholar.google.com/citations?hl=en&user=JpRTl9kAAAAJ">Google Scholar</a>
                <a class="link-black" target="_blank" href="https://github.com/guoxuxu/">GitHub</a>
                <a class="link-black" target="_blank" href="https://www.linkedin.com/in/xu-guo-27ba67175/">LinkedIn</a>
            </div>
        </div>

            <!-- ----- Short Bio block ----- -->

        <div class="profile-bio">
            <div class="bio-title">Short Bio</div>
            <div class="bio-text">
                Dr. Xu Guo is a Researcher at <a class="link-black" target="_blank" href="https://www.kth.se/">KTH, Sweden</a> working with Prof. <a class="link-black" target="_blank" href="https://www.kth.se/profile/skoglund">Mikael Skoglund</a>. She is supported by the prestigious <a class="link-black">Wallenberg-NTU Presidential Postdoctoral Fellowship</a>. Previously, she was a Presidential Postdoctoral Fellow at <a class="link-black" target="_blank" href="https://www.ntu.edu.sg/">NTU, Singapore</a> working with Prof. <a class="link-black" target="_blank" href="https://dr.ntu.edu.sg/entities/person/Miao-Chun-Yan">Chunyan Miao</a>. Before that, she received the Ph.D. degree in 2023 from NTU, Singapore, advised by Prof. <a class="link-black" target="_blank" href="https://federated-learning.org/han.yu/">Han Yu</a>.
                <br>
                <b>Research interests</b>: Natural Language Processing, Generative AI, Efficient AI, Human-AI Communication
            </div>
        </div>

    </div>


    <div class="section-header">
        <a class="section-title" target="_blank" href="https://scholar.google.com/citations?hl=en&user=JpRTl9kAAAAJ">Publications</a>
        <a class="section-view-all" target="_blank" href="https://scholar.google.com/citations?hl=en&user=JpRTl9kAAAAJ">View full list →</a>
    </div>

    <div class="paper-block">
        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/slimsc.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2025.emnlp-main.1750/" target="_blank" class="paper-title">
                    Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency
                </a>
                <div class="paper-authors">Colin Hong*, <b>Xu Guo*</b>, Anand Chaanan Singh, Esha Choukse, Dmitrii Ustiugov</div>
                <i>Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025). <b>Oral</b></i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2025.emnlp-main.1750.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/hyscale-lab/slimsc">Code</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/softcot.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2025.acl-long.1137/" target="_blank" class="paper-title">
                    SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs
                </a>
                <div class="paper-authors">Yige Xu*, <b>Xu Guo*</b>, Zhiwei Zeng, Chunyan Miao</div>
                <i>Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025)</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2025.acl-long.1137.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/xuyige/SoftCoT">Code</a>
                    <a class="paper-btn" target="_blank" href="https://huggingface.co/datasets/xuyige/ASDiv-Aug">Data</a>
                    <a class="paper-btn" target="_blank" href="./poster/softcot.jpeg">Poster</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/seed.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://dl.acm.org/doi/10.1145/3711896.3736909" target="_blank" class="paper-title">
                    Diffusion-Guided Diversity for Single Domain Generalization in Time Series Classification
                </a>
                <div class="paper-authors">Junru Zhang, Lang Feng, <b>Xu Guo</b>, Han Yu, Yabo Dong, Duanqing Xu</div>
                <i>The 32nd ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2025). <b>Oral</b></i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://dl.acm.org/doi/10.1145/3711896.3736909">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://zenodo.org/records/15495436">Code</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/revmux.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2024.emnlp-main.1232/" target="_blank" class="paper-title">
                    RevMUX: Data Multiplexing with Reversible Adapters for Efficient LLM Batch Inference
                </a>
                <div class="paper-authors">Yige Xu, <b>Xu Guo</b>, Zhiwei Zeng, Chunyan Miao</div>
                <i>Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP 2024). <b>Oral. Accepted with scores 5,5,5,3.5</b>. </i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2024.emnlp-main.1232.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/xuyige/RevMUX">Code</a>
                    <a class="paper-btn" target="_blank" href="https://www.youtube.com/watch?v=ZVZszfrKngE">Lecture</a>
                    <a class="paper-btn" target="_blank" href="./poster/revmux.pdf">Poster</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/colm.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a class="paper-title">
                    Generating Synthetic Datasets for Few-shot Prompt Tuning
                </a>
                <div class="paper-authors"><b>Xu Guo</b>, Zilin Du, Boyang Li, Chunyan Miao</div>
                <i>Conference on Language Modeling（COLM 2024）</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://openreview.net/pdf/22a35aecb8e57c14e0f014a23df9807ab7d1a1e1.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="./poster/colm_24.pdf">Poster</a>
                    <a class="paper-btn" target="_blank" href="./slides/colm_24.pdf">Slides</a>
                </div>
            </div>
        </div>

         <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/paircfr.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2024.acl-long.646/" target="_blank" class="paper-title">
                    PairCFR: Enhancing Model Training on Paired Counterfactually Augmented Data through Contrastive Learning
                </a>
                <div class="paper-authors">Xiaoqi Qiu, Yongjie Wang, <b>Xu Guo</b>, Zhiwei Zeng, Yu Yue, Yuhong Feng, Chunyan Miao</div>
                <i>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024)</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2024.acl-long.646.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/Siki-cloud/PairCFR">Code</a>
                    <a class="paper-btn" target="_blank" href="https://underline.io/lecture/103179-paircfr-enhancing-model-training-on-paired-counterfactually-augmented-data-through-contrastive-learning">Lecture</a>
                    <a class="paper-btn" target="_blank" href="./poster/paircfr.pdf">Poster</a>
                </div>
            </div>
        </div>

         <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/intemats.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2023.findings-emnlp.335/" target="_blank" class="paper-title">
                    InteMATs: Integrating Granularity-Specific Multilingual Adapters for Cross-Lingual Transfer
                </a>
                <div class="paper-authors">Meizhen Liu, <b>Xu Guo</b>, Jiakai He, Jianye Chen, Siu Cheung Hui, and Fengyu Zhou</div>
                <i>Findings of the Association for Computational Linguistics: EMNLP 2023</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2023.findings-emnlp.335.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/meizhen-nlp/GranCATs">Code</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/grancats.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://dl.acm.org/doi/10.1145/3583780.3614896" target="_blank" class="paper-title">
                    GranCATs: Cross-Lingual Enhancement through Granularity-Specific Contrastive Adapters
                </a>
                <div class="paper-authors">Meizhen Liu, Jiakai He, <b>Xu Guo</b>, Jianye Chen, Siu Cheung Hui, and Fengyu Zhou</div>
                <i>Conference on Information and Knowledge Management (CIKM 2023)</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://dl.acm.org/doi/10.1145/3583780.3614896">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/meizhen-nlp/GranCATs">Code</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/camel.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://dl.acm.org/doi/10.1145/3581783.3612526" target="_blank" class="paper-title">
                    Training Multimedia Event Extraction With Generated Images and Captions
                </a>
                <div class="paper-authors">Zilin Du, Yunxin Li, <b>Xu Guo</b>, Yidan Sun, and Boyang Li</div>
                <i>ACM Multimedia, 2023</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://dl.acm.org/doi/pdf/10.1145/3581783.3612526">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/ZILIN003/CAMEL">Code</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/fedhumor.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://dl.acm.org/doi/10.1145/3511710" target="_blank" class="paper-title">
                    Federated Learning for Personalized Humor Recognition
                </a>
                <div class="paper-authors"><b>Xu Guo</b>, Han Yu, Boyang Li, Hao Wang, Pengwei Xing, Siwei Feng, Zaiqing Nie, and Chunyan Miao</div>
                <i>ACM Transactions on Intelligent Systems and Technology, 2022</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://arxiv.org/pdf/2012.01675">PDF</a>
                    <a class="paper-btn" target="_blank" href="./slides/fedhumor.pdf">Slides</a>
                    <a class="paper-btn" target="_blank" href="./award/fedhumor.png">Award</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/optima.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2022.findings-emnlp.258/" target="_blank" class="paper-title">
                    Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation
                </a>
                <div class="paper-authors"><b>Xu Guo</b>, Boyang Li, Han Yu</div>
                <i>Findings of the Association for Computational Linguistics: EMNLP 2022</i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2022.findings-emnlp.258.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/guoxuxu/soft-prompt-transfer/tree/main/optima">Code</a>
                    <a class="paper-btn" target="_blank" href="https://underline.io/lecture/65547-improving-the-sample-efficiency-of-prompt-tuning-with-domain-adaptation">Lecture</a>
                </div>
            </div>
        </div>

        <!-- paper item -->
        <div class="paper-item">
            <div class="paper-img-wrapper">
                <img src="./image/pub/loant.png" class="paper-img">
            </div>

            <div class="paper-info">
                <a href="https://aclanthology.org/2021.naacl-main.425/" target="_blank" class="paper-title">
                    Latent-Optimized Adversarial Neural Transfer for Sarcasm Detection
                </a>
                <div class="paper-authors"><b>Xu Guo</b>, Boyang Li, Han Yu, Chunyan Miao</div>
                <i>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL 2021). <b>Oral</b></i>
                <div class="paper-buttons">
                    <a class="paper-btn" target="_blank" href="https://aclanthology.org/2021.naacl-main.425.pdf">PDF</a>
                    <a class="paper-btn" target="_blank" href="https://github.com/guoxuxu/LOANT">Code</a>
                    <a class="paper-btn" target="_blank" href="https://underline.io/lecture/19731-latent-optimized-adversarial-neural-transfer-for-sarcasm-detection">Lecture</a>
                    <a class="paper-btn" target="_blank" href="./award/loant.pdf">Award</a>
                </div>
            </div>
        </div>


    </div>



</div>

<script src="script.js"></script>
</body>
</html>
